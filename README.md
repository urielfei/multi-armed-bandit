<h1> Multi-Armed Bandit <h1>

<h4> 3 Algorithms were checked: <br>
 Lin UCB, UCB, 
 Epsilon Greedy, Greedy bandit, and LinThompson</h4>

Best Algorithm by Reward acumulation


![myplot](myplot.png)


![all_algo_offline_200k_zoom](all_algo_offline_200k_zoom.png)

Lin UCB performed better

